{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><u><H1>Detector de Spam</H1></u></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    words = word_tokenize(text)\n",
    "    tokens = [w for w in words if w.lower() not in string.punctuation]\n",
    "    stopw = stopwords.words('english')\n",
    "    tokens = [token for token in tokens if token not in stopw]\n",
    "    tokens = [word for word in tokens if len(word)>=3]    \n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms001 = ['spam', \"Had your mobile 11 months or more? U R entitled to update to the latest smartphones for Free! Call today The Smartphone Update Co FREE on 08008000800\"]\n",
    "sms002 = ['ham', \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, ok? I've cried enough today.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Had mobile months entitled update latest smartphones Free Call today The Smartphone Update FREE 08008000800'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms001_p = preprocessing(sms001[1])\n",
    "sms001_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"gon home soon n't want talk stuff anymore tonight 've cried enough today\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms002_p = preprocessing(sms002[1])\n",
    "sms002_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/spam.csv', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)\n",
    "df = df.rename(columns = {'v1':'Class','v2':'Text'})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>jurong point crazy.. Available bugis great wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>lar ... Joking wif oni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry wkly comp win Cup final tkts 21st M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>dun say early hor ... already say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah n't think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>FreeMsg Hey darling week word back like fun st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>Even brother like speak They treat like aids p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>per request 'Melle Melle Oru Minnaminunginte N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>WINNER valued network customer selected receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>Had mobile months entitled Update latest colou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "6   ham  Even my brother is not like to speak with me. ...   \n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...   \n",
       "8  spam  WINNER!! As a valued network customer you have...   \n",
       "9  spam  Had your mobile 11 months or more? U R entitle...   \n",
       "\n",
       "                                              Text_p  \n",
       "0  jurong point crazy.. Available bugis great wor...  \n",
       "1                         lar ... Joking wif oni ...  \n",
       "2  Free entry wkly comp win Cup final tkts 21st M...  \n",
       "3              dun say early hor ... already say ...  \n",
       "4         Nah n't think goes usf lives around though  \n",
       "5  FreeMsg Hey darling week word back like fun st...  \n",
       "6  Even brother like speak They treat like aids p...  \n",
       "7  per request 'Melle Melle Oru Minnaminunginte N...  \n",
       "8  WINNER valued network customer selected receiv...  \n",
       "9  Had mobile months entitled Update latest colou...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text_p'] = df['Text'].apply(preprocessing)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a collection of text documents to a Tf-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text_p']\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.0025, max_df=0.1, ngram_range=(1, 2),\n",
    "                         stop_words='english', norm ='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = vectorizer.fit_transform(X)\n",
    "X_train_v = vectorizer.transform(X_train)\n",
    "X_test_v = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'crazy': 127, 'available': 50, 'great': 220, 'world': 597, 'got': 218, 'wat': 568, 'lar': 276, 'wif': 582, 'free': 190, 'entry': 171, 'wkly': 589, 'win': 585, 'final': 182, 'text': 503, 'receive': 427, 'question': 417, 'txt': 541, 'rate': 420, 'apply': 44, 'free entry': 191, 'dun': 162, 'say': 444, 'early': 165, 'think': 511, 'goes': 209, 'freemsg': 192, 'hey': 243, 'week': 573, 'word': 593, 'like': 292, 'fun': 201, 'xxx': 604, 'send': 456, '50': 23, 'brother': 77, 'speak': 483, 'treat': 534, 'set': 462, 'friends': 195, 'winner': 586, 'network': 352, 'customer': 130, 'selected': 454, 'prize': 409, 'claim': 103, 'code': 107, 'valid': 552, 'hours': 253, 'mobile': 337, 'update': 547, 'latest': 279, 'colour': 111, 'camera': 86, 'gon': 212, 'home': 248, 'soon': 479, 'want': 564, 'talk': 499, 'stuff': 491, 'tonight': 529, 've': 554, 'today': 522, 'cash': 92, '100': 4, '000': 0, 'pounds': 404, 'cost': 124, '150p': 10, 'day': 138, '16': 13, 'reply': 429, 'info': 263, 'urgent': 548, 'www': 602, 'net': 351, 'pobox': 400, 'txt word': 543, 'right': 431, 'words': 594, 'thank': 505, 'wont': 592, 'help': 242, 'wonderful': 591, 'times': 520, 'date': 135, 'use': 550, 'credit': 128, 'message': 326, 'http': 256, 'com': 112, 'watching': 571, 'remember': 428, 'yes': 608, 'make': 314, 'fine': 184, 'way': 572, 'feel': 180, 'dont': 151, 'miss': 333, 'news': 356, 'national': 348, 'try': 538, 'going': 211, 'pay': 384, 'aft': 36, 'finish': 185, 'lunch': 311, 'lor': 304, 'ard': 45, 'smth': 478, 'alright': 39, 'meet': 324, 'just': 268, 'eat': 167, 'really': 425, 'tho': 515, 'getting': 204, 'lol': 300, 'did': 146, 'bus': 78, 'mom': 339, 'left': 282, 'dinner': 148, 'love': 307, 'amp': 40, 'car': 87, 'll': 297, 'let': 286, 'know': 272, 'room': 435, 'let know': 287, 'work': 595, 'wait': 559, 'sure': 495, 'live': 296, 'yeah': 605, 'till': 518, 'tell': 501, 'thanks': 506, 'ringtone': 433, 'month': 341, 'yup': 610, 'look': 302, 'msg': 344, '2nd': 21, 'lesson': 285, 'hello': 241, 'saturday': 442, 'decided': 141, 'tomo': 525, 'trying': 539, 'pls': 396, 'wanted': 566, 'weekend': 574, 'forget': 188, 'need': 350, 'sweet': 496, 'tried': 535, 'sms': 477, 'nokia': 363, 'camcorder': 84, '08000930705': 2, 'delivery': 143, 'tomorrow': 526, 'seeing': 453, 'hope': 249, 'man': 317, 'calls': 83, 'messages': 327, 'missed': 334, 'maybe': 320, 'ask': 46, 'bit': 67, 'time': 519, 'saw': 443, 'class': 104, 'half': 230, 'second': 451, 'morning': 342, 'place': 392, 'thought': 516, 'best': 63, 'happy': 233, 'sorry': 480, 'new': 354, 'play': 394, 'end': 169, 'yesterday': 609, 'congrats': 118, 'year': 606, 'special': 484, 'later': 278, 'meeting': 325, 'sorry ll': 481, 'll later': 298, 'pick': 389, 'pain': 381, 'good': 214, 'girls': 207, 'took': 530, 'come': 113, 'double': 153, 'check': 99, 'hair': 229, 'said': 440, 'nice': 358, 'mob': 336, 'awarded': 54, 'bonus': 68, 'frnds': 198, 'trip': 536, '1000': 5, 'dis': 149, '18': 14, 'hear': 239, 'comes': 115, 'lucky': 310, 'money': 340, 'finished': 186, 'babe': 57, 'wan': 563, 'waiting': 560, 'thats': 508, 'cool': 122, 'looking': 303, 'job': 265, 'stop': 489, 'real': 424, 'used': 551, 'started': 486, 'came': 85, 'bed': 61, 'wen': 578, 'don': 150, 'close': 105, 'night': 360, 'late': 277, 'afternoon': 37, 'means': 322, 'smile': 475, 'smiling': 476, 'service': 460, 'won': 590, 'guaranteed': 222, '5000': 25, 'customer service': 131, '1000 cash': 6, 'havent': 237, 'buy': 80, 'movie': 343, 'abt': 31, 'run': 437, 'forgot': 189, 'cause': 93, 'prob': 412, 'okay': 369, 'price': 406, 'long': 301, 'gone': 213, 'driving': 159, 'test': 502, 'mean': 321, 'guess': 224, 'search': 450, 'says': 446, 'life': 290, 'lot': 305, 'dear': 140, 'birthday': 66, 'making': 316, 'aight': 38, 'hit': 244, 'address': 35, 'old': 371, 'people': 385, 'better': 64, 'worry': 598, 'busy': 79, 'cos': 123, 'things': 510, 'contact': 120, 'draw': 154, 'shows': 468, '12hrs': 8, '150ppm': 12, 'trying contact': 540, 'draw shows': 155, 'prize guaranteed': 411, 'valid 12hrs': 553, 'juz': 269, 'haha': 228, 'happened': 232, 'went': 579, 'holiday': 247, 'operator': 374, 'min': 328, 'selected receive': 455, 'friday': 193, 'hmm': 245, 'school': 448, 'food': 187, 'private': 408, 'account': 32, 'statement': 487, 'points': 401, 'identifier': 259, 'expires': 174, 'account statement': 33, 'identifier code': 260, '2000': 16, 'landline': 275, 'urgent mobile': 549, 'todays': 523, 'award': 53, 'wat time': 569, 'sent': 459, 'girl': 206, 'answer': 42, 'quiz': 419, 'player': 395, 'join': 266, 'haf': 227, 'msgs': 345, 'chat': 98, 'services': 461, 'type': 544, 'sir': 470, 'mail': 313, 'little': 295, 'coz': 126, 'gud': 223, 'ni8': 357, 'open': 373, 'whats': 580, 'taking': 498, 'sexy': 463, 'luv': 312, 'hard': 235, 'thk': 514, 'lots': 306, 'leaving': 281, 'house': 254, 'boy': 73, 'missing': 335, 'years': 607, 'parents': 382, 'friend': 194, 'frnd': 197, 'send stop': 458, 'order': 377, 'content': 121, 'fancy': 177, 'liao': 289, 'coming': 116, 'believe': 62, 'ill': 261, 'carlos': 90, 'til': 517, 'worth': 599, 'log': 299, 'offer': 366, 'gr8': 219, 'guys': 226, 'working': 596, 'boytoy': 74, 'awesome': 56, 'minute': 331, 'xmas': 603, 'jus': 267, 'sis': 471, 'uk': 545, 'touch': 532, 'finally': 183, 'course': 125, 'able': 30, 'hav': 236, 'nice day': 359, 'story': 490, 'tmr': 521, 'evening': 173, 'darlin': 133, 'college': 110, 'decimal': 142, 'goodmorning': 217, 'sleeping': 474, 'dat': 134, 'oso': 379, 'oredi': 378, 'big': 65, 'ready': 423, 'break': 75, 'noe': 362, 'leh': 283, 'sounds': 482, 'easy': 166, 'called': 81, 'important': 262, 'shop': 466, 'happen': 231, 'nite': 361, '500': 24, 'collect': 108, 'start': 485, 'company': 117, 'good morning': 215, 'walk': 562, '10p': 7, 'wil': 584, 'reach': 421, 'person': 386, 'secret': 452, 'thinks': 513, 'case': 91, 'tel': 500, 'meant': 323, 'told': 524, 'face': 175, 'watch': 570, 'thanx': 507, 'asked': 47, 'didnt': 147, 'wake': 561, 'sleep': 473, 'good night': 216, 'congratulations': 119, 'vouchers': 558, 'music': 347, 'hold': 246, 'angry': 41, 'wid': 581, 'true': 537, 'care': 89, 'takes': 497, 'video': 555, '750': 26, 'anytime': 43, 'mins': 330, 'reply 08000930705': 430, 'shopping': 467, 'ring': 432, 'hot': 251, 'unsubscribe': 546, 'plan': 393, 'choose': 102, 'club': 106, 'wk': 588, 'charge': 97, '86688': 29, 'far': 178, 'okie': 370, 'guy': 225, 'lets': 288, 'ok': 368, 'baby': 58, 'hour': 252, 'shall': 464, 'phone': 387, 'card': 88, 'hurt': 258, 'plz': 399, 'pick phone': 390, 'pls send': 397, 'send message': 457, 'shit': 465, 'book': 69, 'friendship': 196, 'games': 203, 'tones': 528, 'sister': 472, 'weekly': 575, 'box': 72, 'wot': 600, 'great day': 221, 'dunno': 163, 'dude': 161, 'problem': 414, 'read': 422, 'light': 291, 'line': 293, 'number': 365, 'chance': 94, '150p msg': 11, 'calling': 82, 'post': 403, 'texts': 504, 'jay': 264, 'minutes': 332, 'suite342': 492, '2lands': 19, 'row': 436, 'suite342 2lands': 493, '2lands row': 20, 'chikku': 101, 'new year': 355, 'orange': 376, 'mobileupd8': 338, '08000839402': 1, 'wish': 587, 'project': 415, 'quite': 418, 'reason': 426, 'leave': 280, 'huh': 257, 'sat': 441, 'office': 367, 'days': 139, 'bout': 71, 'actually': 34, 'god': 208, 'change': 96, 'poly': 402, 'tone': 527, '1st': 15, 'txt stop': 542, 'stay': 488, 'drink': 157, 'thing': 509, 'den': 144, 'bring': 76, 'dating': 136, 'dating service': 137, '250': 18, 'head': 238, 'heart': 240, 'eve': 172, 'land': 273, '2000 prize': 17, 'land line': 274, 'line claim': 294, 'mind': 329, 'fucking': 200, 'tot': 531, 'hope good': 250, 'welcome': 577, 'beautiful': 60, 'kind': 270, 'bad': 59, 'feeling': 181, 'opt': 375, 'princess': 407, 'enjoy': 170, 'sae': 439, 'details': 145, 'cum': 129, 'thinking': 512, 'visit': 556, 'nope': 364, 'prize claim': 410, 'bored': 70, 'outside': 380, 'attempt': 48, '2nd attempt': 22, 'attempt contact': 49, '150': 9, 'pretty': 405, '800': 27, 'shows 800': 469, 'kiss': 271, 'sea': 449, 'probably': 413, 'online': 372, 'pics': 391, 'fast': 179, 'fuck': 199, 'mum': 346, 'sch': 447, 'wife': 583, 'chance win': 95, '10': 3, 'neva': 353, 'want come': 565, 'game': 202, 'family': 176, 'pub': 416, 'voucher': 557, 'weeks': 576, 'dad': 132, 'email': 168, 'town': 533, 'sun': 494, 'saying': 445, 'come home': 114, 'รป_': 611, 'away': 55, 'wants': 567, 'rite': 434, 'makes': 315, 'happy new': 234, 'goin': 210, 'drive': 158, 'lovely': 308, 'national rate': 349, 'mates': 319, 'gift': 205, '8007': 28, 'mate': 318, 'await': 51, 'collection': 109, 'await collection': 52, 'drop': 160, 'dont know': 152, 'sad': 438, 'plus': 398, 'wrong': 601, 'earlier': 164, 'loving': 309, 'party': 383, 'pic': 388, 'chennai': 100, 'dreams': 156, 'hows': 255, 'lei': 284}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "612"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 612)\n",
      "(3900, 612)\n",
      "(1672, 612)\n"
     ]
    }
   ],
   "source": [
    "print(X_std.shape)\n",
    "print(X_train_v.shape)\n",
    "print(X_test_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ll</td>\n",
       "      <td>0.017225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>like</td>\n",
       "      <td>0.017010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>come</td>\n",
       "      <td>0.016933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>know</td>\n",
       "      <td>0.016252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>time</td>\n",
       "      <td>0.015840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>got</td>\n",
       "      <td>0.015685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>home</td>\n",
       "      <td>0.014387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>good</td>\n",
       "      <td>0.014292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>want</td>\n",
       "      <td>0.013994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>going</td>\n",
       "      <td>0.013639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>free</td>\n",
       "      <td>0.013104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>day</td>\n",
       "      <td>0.012225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>need</td>\n",
       "      <td>0.012026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>love</td>\n",
       "      <td>0.011948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>lor</td>\n",
       "      <td>0.011943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>send</td>\n",
       "      <td>0.011721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>dont</td>\n",
       "      <td>0.011219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>text</td>\n",
       "      <td>0.011129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>think</td>\n",
       "      <td>0.011013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>tell</td>\n",
       "      <td>0.010598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      term    weight\n",
       "297     ll  0.017225\n",
       "292   like  0.017010\n",
       "113   come  0.016933\n",
       "272   know  0.016252\n",
       "519   time  0.015840\n",
       "218    got  0.015685\n",
       "248   home  0.014387\n",
       "214   good  0.014292\n",
       "564   want  0.013994\n",
       "211  going  0.013639\n",
       "190   free  0.013104\n",
       "138    day  0.012225\n",
       "350   need  0.012026\n",
       "307   love  0.011948\n",
       "304    lor  0.011943\n",
       "456   send  0.011721\n",
       "151   dont  0.011219\n",
       "503   text  0.011129\n",
       "511  think  0.011013\n",
       "501   tell  0.010598"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray(X_train_v.mean(axis=0)).ravel().tolist()\n",
    "weights_df = pd.DataFrame({'term': vectorizer.get_feature_names(), 'weight': weights})\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB().fit(X_train_v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb_model.predict(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9808612440191388\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1446    6]\n",
      " [  26  194]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores:[0.98566308 0.97849462 0.97311828 0.97849462 0.96774194 0.97307002\n",
      " 0.97845601 0.98381295 0.97482014 0.97302158]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(nb_model, X_std, y, cv=10)\n",
    "print(f\"Cross Val Scores:{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores Mean:0.9766693253377838 / Cross Val Scores Std:0.00513579057166201\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross Val Scores Mean:{scores.mean()} / Cross Val Scores Std:{scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_svm = SVC(gamma='scale', kernel='rbf', C=10).fit(X_train_v, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = cls_svm.predict(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9832535885167464\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1449    3]\n",
      " [  25  195]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores:[0.9874552  0.97491039 0.97849462 0.98566308 0.96953405 0.97666068\n",
      " 0.97845601 0.97661871 0.98201439 0.97841727]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(cls_svm, X_std, y, cv=10)\n",
    "print(f\"Cross Val Scores:{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Scores Mean:0.9788224403971348 / Cross Val Scores Std:0.004929718538649726\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cross Val Scores Mean:{scores.mean()} / Cross Val Scores Std:{scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "https://www.nltk.org/data.html\n",
    "\n",
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "http://www.nltk.org/book/ch06.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
